[
  {
    "source": "motherduck_docs",
    "url": "https://motherduck.com/docs/getting-started/e2e-tutorial/part-2/",
    "title": "2 - Loading Your Data | MotherDuck Docs",
    "content": "2 - Loading Your Data | MotherDuck Docs Skip to main contentSLACK COMMUNITYDUCKDB SNIPPETSBLOGllmsSearchSIGN UPGetting startedMotherDuck Tutorial1 - First Query2 - Loading Data3 - Sharing DataData WarehousingCustomer-Facing AnalyticsInterfacesExample DatasetsReferenceHow-to guidesIntegrationsConceptsTroubleshootingAbout MotherDuckGetting startedMotherDuck Tutorial2 - Loading DataCopy as MarkdownOn this page2 - Loading Your DataIn this section, you'll learn how to load your own data into MotherDuck and run powerful hybrid queries that combine local and cloud data. \ud83d\udc48 Go back to Part 1: Running Your First Query Loading your data\u200b Loading Data using CREATE TABLE AS SELECT\u200b The CREATE TABLE AS SELECT (CTAS) pattern creates a new table and populates it with data in a single operation: CREATE OR REPLACE TABLE docs_playground.my_table AS SELECT * FROM 'my_data.csv'; Loading Data using INSERT INTO\u200b The INSERT INTO pattern allows you to append data to existing tables, update specific records, and manage data incrementally: -- First, create the table structureCREATE TABLE docs_playground.my_table AS SELECT * FROM 'my_data.csv' LIMIT 0;-- Then load data incrementallyINSERT INTO docs_playground.my_table SELECT * FROM 'new_data.csv';INSERT OR REPLACE INTO docs_playground.my_table SELECT * FROM 'updated_data.csv'; tipWhile CREATE TABLE AS SELECT is convenient for one-time loads or small datasets, for larger datasets and production workflows, we recommend using INSERT INTO. This approach provides better control over data loading, allows for incremental updates, and is more efficient for ongoing data management. There are several ways to get your data into MotherDuck, depending on where your data currently lives: From Local File System\u200b To load data files from your file system into MotherDuck, you'll need: A valid MotherDuck token stored as the motherduck_token environment variable A DuckDB client (DuckDB CLI, Python, etc.) To create a MotherDuck token, navigate to the MotherDuck UI, click your organization name in the top left, then go to Settings > Integrations > Access Token. For detailed instructions, see our authentication guide. DuckDB CLIPythonMotherDuck UIInstall the DuckDB CLI for macOS/Linux. For other operating systems, see the DuckDB installation guide.curl https://install.duckdb.org | shLaunch the DuckDB CLI:duckdb-- Connect to MotherDuckATTACH 'md:';-- Load CSV data from your local file into the playground databaseCREATE TABLE docs_playground.popular_currency_rate_dollar AS SELECT * FROM './popular_currency_rate_dollar.csv';Install DuckDB using your preferred package manager, such as pip:pip install duckdbimport duckdb# Connect to MotherDuckconn = duckdb.connect('md:')# Load data into the playground database (automatically created)conn.execute(\"\"\" CREATE TABLE docs_playground.popular_currency_rate_dollar AS SELECT * FROM './popular_currency_rate_dollar.csv'\"\"\")Head over to the Create table from file button in the MotherDuck UI and upload your file directly. This works great for smaller files and provides a visual interface. From Remote Storage (S3, GCS, etc.)\u200b For data already stored in cloud storage, you have multiple options: SQLDuckDB CLIPythonYou can run queries directly against remote storage using our interactive SQL editor:CREATE TABLE IF NOT EXISTS docs_playground.popular_currency_rate_dollar AS SELECT * FROM 's3://us-prd-motherduck-open-datasets/misc/csv/popular_currency_rate_dollar.csv';SQL Editor loading...ATTACH 'md:';CREATE TABLE docs_playground.popular_currency_rate_dollar AS SELECT * FROM 's3://us-prd-motherduck-open-datasets/misc/csv/popular_currency_rate_dollar.csv';import duckdbconn = duckdb.connect('md:')conn.execute(\"\"\" CREATE TABLE docs_playground.popular_currency_rate_dollar AS SELECT * FROM 's3://your-bucket/your-file.csv'\"\"\") infoFor private AWS s3 buckets, you'll need to configure AWS credentials. Check our AWS s3 authentication guide for details. Querying Your Data\u200b Once your data is loaded, you can query it from any interface: SQLDuckDB CLIPythonFROM docs_playground.popular_currency_rate_dollar LIMIT 10;SQL Editor loading...ATTACH 'md:';FROM docs_playground.popular_currency_rate_dollar LIMIT 10;import duckdb# Connect to MotherDuckconn = duckdb.connect('md:')# Query your dataresult = conn.sql(\"FROM docs_playground.popular_currency_rate_dollar LIMIT 10\").fetchall()print(result) \ud83d\udc49 Continue to Part 3: Sharing Your Database \u2192Previous1 - First QueryNext3 - Sharing DataLoading your dataLoading Data using CREATE TABLE AS SELECTLoading Data using INSERT INTOFrom Local File SystemFrom Remote Storage (S3, GCS, etc.)Querying Your DataMotherDuckDocs Pricing ProductOverview For Data Teams For App Devs For DuckDB Users Case Studies Ecosystem Startups Support Trust & Security CommunityBlog Slack Events YouTube Small Data SF Videos & Streams DuckDB News DuckDB Snippets Free DuckDB Book Learn Code of Conduct CompanyAbout Us Careers Quacking Contact Support MotherDuck is powered by DuckDBTerms of UsePrivacy PolicySupport Policy",
    "length": 5026
  },
  {
    "source": "motherduck_docs",
    "url": "https://motherduck.com/docs/getting-started/e2e-tutorial/part-3/",
    "title": "3 - Sharing Your Database | MotherDuck Docs",
    "content": "3 - Sharing Your Database | MotherDuck Docs Skip to main contentSLACK COMMUNITYDUCKDB SNIPPETSBLOGllmsSearchSIGN UPGetting startedMotherDuck Tutorial1 - First Query2 - Loading Data3 - Sharing DataData WarehousingCustomer-Facing AnalyticsInterfacesExample DatasetsReferenceHow-to guidesIntegrationsConceptsTroubleshootingAbout MotherDuckGetting startedMotherDuck Tutorial3 - Sharing DataCopy as MarkdownOn this page3 - Sharing Your DatabaseIn this section, you'll learn how to share your databases with colleagues and collaborate effectively using MotherDuck's sharing features. \ud83d\udc48 Go back to Part 2: Loading Your Dataset Creating and Sharing Your Data\u200b Let's create a table with sample data in your playground database, then share it with others. The docs_playground database is automatically created when you connect, so you can start experimenting right away! First, let's populate your playground database with some currency exchange data: CREATE TABLE docs_playground.currency_rates AS SELECT 'USD' AS currency_code, 'US Dollar' AS currency_name, 1.0 AS rate_to_usd, '2024-01-15' AS rate_date UNION ALL SELECT 'EUR', 'Euro', 0.85, '2024-01-15' UNION ALL SELECT 'GBP', 'British Pound', 0.75, '2024-01-15' UNION ALL SELECT 'JPY', 'Japanese Yen', 110.0, '2024-01-15';SQL Editor loading... Sharing your database\u200b With your database and sample data in place, you can now share this dataset with others. MotherDuck shares create a point-in-time snapshot of your database that can be accessed by specified users or groups. When creating a share, the most important parameters control access scope, visibility, and update behavior. By default, shares use ACCESS ORGANIZATION (only your organization members can access), VISIBILITY DISCOVERABLE (appears in your organization's shared database list), and UPDATE MANUAL (creates a static snapshot that doesn't auto-update). The syntax to create a share visible to everyone in your Organization is CREATE SHARE <share name> from <database name>. SQLMotherDuck UICREATE SHARE IF NOT EXISTS currency_data_share FROM docs_playground (ACCESS ORGANIZATION, VISIBILITY DISCOVERABLE);SQL Editor loading...You can also create shares through the MotherDuck UI by clicking the dropdown menu next to your database and selecting the share option. This will open a window to configure your share settings. Once created, all members of your organization will be able to view this share in the MotherDuck UI under \"Shared with me\". Learn more about sharing in MotherDuck here. Understanding Share Configuration\u200b When creating shares, you can control three key aspects: who can access the data, how users discover the share, and when the data updates. Each parameter has specific options that determine the sharing behavior. ACCESS - Who Can Access the Share\u200b ACCESS ORGANIZATION (default): Only members of your organization can access the share ACCESS UNRESTRICTED: All MotherDuck users across all organizations can access the share ACCESS RESTRICTED: Only the share owner has initial access; additional users must be granted access via GRANT commands VISIBILITY - How Users Discover the Share\u200b VISIBILITY DISCOVERABLE (default): The share appears in your organization's \"Shared with me\" section for easy discovery VISIBILITY HIDDEN: Share can only be accessed via direct URL; not listed in any user interface Important Visibility Rules Organization and Restricted shares default to DISCOVERABLE Unrestricted shares can only be HIDDEN Hidden shares can only be used with ACCESS RESTRICTED UPDATE - When Share Data Updates\u200b UPDATE MANUAL (default): Share content only updates when you run UPDATE SHARE command UPDATE AUTOMATIC: Share automatically reflects database changes within ~5 minutes Example Share Configurations\u200b -- Organization share (most common) CREATE SHARE IF NOT EXISTS team_currency_analysis FROM docs_playground ( ACCESS ORGANIZATION, VISIBILITY DISCOVERABLE, UPDATE MANUAL );SQL Editor loading... -- Restricted share for selective access CREATE SHARE IF NOT EXISTS private_analysis FROM docs_playground ( ACCESS RESTRICTED, VISIBILITY HIDDEN, UPDATE AUTOMATIC );SQL Editor loading... Querying Shared Data\u200b After creating a share, authorized users can access the shared database in two ways: by using the share URL directly or by attaching it as a database alias: -- Attach a shared databaseATTACH 'md:_share/docs_playground/b556630d-74f1-435c-9459-cfb87d349cb3' AS shared_currency;-- Query the shared dataSELECT * FROM shared_currency.currency_rates WHERE rate_to_usd < 1.0ORDER BY rate_to_usd DESC; Managing Shares\u200b You can also manage your existing shares: SELECT name, source_db_name, access, visibility FROM MD_INFORMATION_SCHEMA.OWNED_SHARES WHERE name LIKE '%currency%';SQL Editor loading... Going further\u200b Now that you've mastered the basics, here are some next steps to explore: Learn about MotherDuck's Dual Execution feature Connect to your favorite BI tools: Tableau, Power BI and learn more about read scaling Set up data pipelines with dbt Look at our supported integrations to integrate with your data stack. Previous2 - Loading DataNextData WarehousingCreating and Sharing Your DataSharing your databaseUnderstanding Share ConfigurationACCESS - Who Can Access the ShareVISIBILITY - How Users Discover the ShareUPDATE - When Share Data UpdatesExample Share ConfigurationsQuerying Shared DataManaging SharesGoing furtherMotherDuckDocs Pricing ProductOverview For Data Teams For App Devs For DuckDB Users Case Studies Ecosystem Startups Support Trust & Security CommunityBlog Slack Events YouTube Small Data SF Videos & Streams DuckDB News DuckDB Snippets Free DuckDB Book Learn Code of Conduct CompanyAbout Us Careers Quacking Contact Support MotherDuck is powered by DuckDBTerms of UsePrivacy PolicySupport Policy",
    "length": 5770
  },
  {
    "source": "motherduck_docs",
    "url": "https://motherduck.com/docs/getting-started/data-warehouse/",
    "title": "Data Warehousing Guide | MotherDuck Docs",
    "content": "Data Warehousing Guide | MotherDuck Docs Skip to main contentSLACK COMMUNITYDUCKDB SNIPPETSBLOGllmsSearchSIGN UPGetting startedMotherDuck TutorialData WarehousingCustomer-Facing AnalyticsInterfacesExample DatasetsReferenceHow-to guidesIntegrationsConceptsTroubleshootingAbout MotherDuckGetting startedData WarehousingCopy as MarkdownOn this pageData Warehousing GuideIntroduction to MotherDuck for Data Warehousing\u200b MotherDuck is a cloud-native data warehouse built on top of DuckDB that adds enterprise features like cloud storage, sharing, and collaboration to DuckDB's fast analytical engine. The platform serves these needs through its serverless architecture, sharing model, and WASM capabilities. It benefits data analysts with AI-assisted SQL, data engineers with familiar tools like dbt, and data scientists with hybrid local-cloud processing. MotherDuck integrates with popular data tools including Estuary, Fivetran, and Airbyte for data ingestion, dbt for transformations, Tableau and PowerBI for visualization, and Airflow and Dagster for orchestration. This enables teams to build data warehousing solutions using their existing tools. Data Ingestion\u200b An easy way to get into MotherDuck is using ecosystem partners like Estuary, Fivetran, dlthub, and Airbyte but you can also create custom data engineering pipelines. MotherDuck is very flexible with how to load your data: From data you have on your filesystem: If you have CSVs, JSON files or DuckDB databases sitting around, It's easy to load it into your MotherDuck data warehouse. From a data lake on a cloud object store: If you already have your data in a data lake, as parquet, delta, iceberg or other formats, DuckDB has abstractions for Secrets, Object Storage, and many file types. When combined, this means that many file types can be read into DuckDB from Object Storage with only SQL. Though not as performant as MotherDuck's native storage layer, you can also query your infrequently-accessed data directly from your data lake with MotherDuck. Using Native APIs in many languages: DuckDB supports numerous languages such as C++, Python, and Java, in addition to its own mostly Postgres-compatible SQL dialect. Using these languages, Data Engineers and Developers can easily integrate with MotherDuck without having to pick up yet-another-language. Best Practices for Programmatic Loading\u200b The fastest way to load data is to load single tables in large batches, saturating the network connection between MotherDuck and the source data. DuckDB is incredibly good at handling both files and some kinds of in-memory objects, like Arrow dataframes. As an aside, Parquet files compress at 5-10x compared to CSV, which means you can get 5-10x more throughput simply by using Parquet files. Similarly, open table formats like Delta & Iceberg share those performance gains. On the other hand, small writes on multiple tables will lead to suboptimal performance. While MotherDuck does indeed offer ACID compliance, it is not an OLTP system like Postgres! Significantly better performance can be achieved by using queues to batch writes to tables. While some latency is introduced with this methodology, the improvement in throughput should far outweigh the cost of doing small writes. Streaming workloads are better suited to be handled with queues in front of MotherDuck. Transforming Data\u200b Once data is loaded into MotherDuck, it must be transformed into a model that matches the business purpose and needs. This can be done directly in MotherDuck using the powerful library of SQL functions offered by DuckDB. Many data engineers prefer to use data transformation tools like the open source dbt Core. More details specifically about using dbt with MotherDuck can be read in the blog on this topic. For more in-depth reading, the free DuckDB in Action eBook explores these concepts with real-world examples. Sharing Data\u200b Once your data is loaded into MotherDuck and appropriately transformed for use by your analysts, you can make that data available using MotherDuck's sharing capabilities. This can allow every user in your organization to access the data warehouse in the MotherDuck UI, in their Python code or with other tools. Admins don't need to worry that the queries run by users will impact their data pipelines as users have isolated compute. Serving Data Analytics\u200b Do you want to serve reports or dashboards for your users? MotherDuck provides tokens that can be used with popular tools like Tableau & Power BI to access your data warehouse to serve business intelligence to end users. Ducks all the Way Down: Building Data Apps\u200b MotherDuck is built on DuckDB because it is an extremely efficient SQL engine inside a ~20MB executable. This allows you to run the same DuckDB engine which powers your data warehouse inside your web browser, creating highly-interactive visualizations with near-zero latency. This enhances your experience when using the Column Explorer in the MotherDuck UI. One thing that is unique to MotherDuck is its capabilities for serving data into the web layer via WASM. These capabilities enable novel analytical user actions, including very intensive queries that would be prohibitively expensive in other query engines. It also supports data mashup from various sources, so that data in the warehouse can easily be combined with other sources, like files in CSV, JSON, or Parquet. Scaling up & out for DWH use cases\u200b Furthermore, MotherDuck has a unique scaling model, of which there are four key concepts relevant for Data Warehousing. Vertical Scaling\u200b Compute can scale up with larger instances - currently, we offer 4 sizes by default: Pulse, Standard, Jumbo, and Mega. To get access to even larger instance types, please contact us. Unlike other data warehouses, every instance is isolated from each other: one user's queries will not impact another user's from completing. This per-user tenancy concept assures you can size your warehouse correctly and use your resources very efficently. Horizontal Scaling\u200b For serving data to BI tools or other spiky consumers, Read-Scaling Replicas can absorb the loads and maintain low latency on user interactivity. These should be owned by the same user or service accounts that run production jobs, although they can also leverage SHARES depending on preferences. Per-user tenancy\u200b Especially for production runs, user should leverage seperate user or service accounts with their own dedicated compute for updating and maintaining core tables. Distributed DuckDB\u200b DuckDB and MotherDuck work together as a distributed system that automatically optimizes query execution between local and cloud resources through Dual Execution, enabling efficient data access regardless of location. Orchestration\u200b In order to keep data up to date inside of MotherDuck, often an orchestrator like Airflow or Dagster can be used. This runs jobs in specific orders to load & transform data, as well managing workflow and observability, which is necessary for handling more complex data engineering pipelines. If this is your first data warehouse, you might consider starting with something as simple as GitHub actions or cron jobs to orchestrate your data pipelines. infoFor a more in-depth guide, check out the Data Warehousing Guide Need Help Along the Way?\u200b Please do not hesitate to contact us if you need help along your journey. We are here to help you succeed with your data warehouse!Previous3 - Sharing DataNextCustomer-Facing AnalyticsIntroduction to MotherDuck for Data WarehousingData IngestionBest Practices for Programmatic LoadingTransforming DataSharing DataServing Data AnalyticsDucks all the Way Down: Building Data AppsScaling up & out for DWH use casesVertical ScalingHorizontal ScalingPer-user tenancyDistributed DuckDBOrchestrationNeed Help Along the Way?MotherDuckDocs Pricing ProductOverview For Data Teams For App Devs For DuckDB Users Case Studies Ecosystem Startups Support Trust & Security CommunityBlog Slack Events YouTube Small Data",
    "length": 8208
  },
  {
    "source": "motherduck_docs",
    "url": "https://motherduck.com/docs/getting-started/customer-facing-analytics/",
    "title": "Customer-Facing Analytics Guide | MotherDuck Docs",
    "content": "Customer-Facing Analytics Guide | MotherDuck Docs Skip to main contentSLACK COMMUNITYDUCKDB SNIPPETSBLOGllmsSearchSIGN UPGetting startedMotherDuck TutorialData WarehousingCustomer-Facing AnalyticsInterfacesExample DatasetsReferenceHow-to guidesIntegrationsConceptsTroubleshootingAbout MotherDuckGetting startedCustomer-Facing AnalyticsCopy as MarkdownOn this pageCustomer-Facing Analytics GuideMotherDuck's architecture is designed for the unique requirements of Customer-Facing Analytics (CFA). Per-user tenancy model, providing each of your customers with dedicated databases and compute resources that can scale up, scale down and scale out as needed. Dual Execution. Enabled by the ultra-lightweight architecture of DuckDB, each MotherDuck client is also capable of processing SQL queries. This enables you to provide your customers with nearly instantaneous filtering and drilldown of their data, like Column Explorer and Instant SQL provide for MotherDuck users. This article will help you understand how the MotherDuck architecture compares to traditional transactional and analytic databases. We'll also give you some next steps for building your applications. infoWhat's the difference with BI? Business Intelligence (BI) is traditionally built for internal stakeholders\u2014it runs on batch-processed data models, serves a small number of users, and tolerates high-latency queries. In contrast, customer-facing analytics is built directly into your product for end users. It delivers near real-time, low-latency insights at scale\u2014think milliseconds, not minutes\u2014and must handle thousands to millions of concurrent queries. While BI powers strategic decisions in the boardroom, user-facing analytics drives engagement and value directly in the app experience. Architectural Considerations\u200b For many types of applications, the data sits in a transactional database (OLTP database) like Postgres or MySQL. Engineers building CFA features often run analytical queries directly in a multi-tenant transactional database, which works fine until things break down at scale. Row-based storage and transactional databases simply aren't designed for efficient analytical querying. Switching to a database and query engine designed for analytics is the first step. However, many of the legacy OLAP engines were designed with only the internal analytics/bi use case in mind. They are provisioned as a single instance (or cluster) for all customer data, leading to overprovisioning of resources for peak load and a terrible 'noisy neighbor' problem in addition to latency and underlying security concerns. MotherDuck provisions a Duckling (DuckDB instance) for each of your customers (or even for each of your customers' users) for these use cases. This \"hyper-tenancy\" model isolates customer data and provides the same great DuckDB-powered experience for each individual user. Critically, this means as your application scales, you can simply add more capacity for your users in a much more cost effective way than a traditional database architecture. Scaling Analytics Up and Out\u200b Each of your customers (and possibly each of their users) has their own MotherDuck Duckling (DuckDB instance). This means that one account could run several hundred or thousands of Ducklings at a given time, or none at all. This type of serverless model is at the heart of MotherDuck's advantage versus other engines. And of course, it's not just limited to more Ducklings: What if a customer needs to have more compute power or memory? MotherDuck has several instance sizes to scale up for even larger workloads. You can scale vertically by upgrading (or downgrading) the instance size your application uses for each customer, enabling you to provide more power for more important customers. This is likely all you need to scale your application for customers, but if you need even more compute or the ability to handle high concurrency, you can launch read scaling Ducklings for your compute-hungry customers. Dual Execution for Zero-Latency Data Exploration\u200b As you're building Customer-Facing Analytics into your product, you want to provide an experience that wows your customers. Legacy data warehouses rarely provide sub-second response times, making it difficult to enable your customers to quickly explore their data. MotherDuck, through the efficiency of DuckDB, already makes this better with faster query response times, but what if you want near-zero latency? Because the same DuckDB SQL engine runs on both MotherDuck Ducklings and on your customers' machines, you can offload some data processing to their laptops and provide instant data exploration, filtering, sorting, etc using SQL queries. Customers don't even need to install anything on their computers as DuckDB runs inside the web browser using a technology called Web Assembly (Wasm). You can see examples of the experience enabled by this architecture by checking out Column Explorer and Instant SQL in the MotherDuck UI. Here's a teaser of it in action: Getting started with Customer-Facing Analytics and MotherDuck\u200b To get started with Customer-Facing Analytics and MotherDuck, check out our How-To Guide for Customer-Facing Analytics page.PreviousData WarehousingNextMotherDuck InterfacesArchitectural ConsiderationsScaling Analytics Up and OutDual Execution for Zero-Latency Data ExplorationGetting started with Customer-Facing Analytics and MotherDuckMotherDuckDocs Pricing ProductOverview For Data Teams For App Devs For DuckDB Users Case Studies Ecosystem Startups Support Trust & Security CommunityBlog Slack Events YouTube Small Data SF Videos & Streams DuckDB News DuckDB Snippets Free DuckDB Book Learn Code of Conduct CompanyAbout Us Careers Quacking Contact Support MotherDuck is powered by DuckDBTerms of UsePrivacy PolicySupport Policy",
    "length": 5802
  },
  {
    "source": "motherduck_docs",
    "url": "https://motherduck.com/docs/getting-started/interfaces/client-apis/connect-query-from-python/installation-authentication/",
    "title": "Installation & authentication | MotherDuck Docs",
    "content": "Installation & authentication | MotherDuck Docs Skip to main contentSLACK COMMUNITYDUCKDB SNIPPETSBLOGllmsSearchSIGN UPGetting startedMotherDuck TutorialData WarehousingCustomer-Facing AnalyticsInterfacesClient APIsPythonInstallation & authenticationSpecify MotherDuck databaseLoading data into MotherDuckQuery dataCGoJava (JDBC)Node.jsODBCOthersRRustWebAssembly (Wasm)DuckDB CLIMotherDuck Web UIExample DatasetsReferenceHow-to guidesIntegrationsConceptsTroubleshootingAbout MotherDuckGetting startedInterfacesClient APIsPythonInstallation & authenticationCopy as MarkdownOn this pageInstallation & authenticationPrerequisites\u200b MotherDuck Python supports the following operating systems: Linux (x64, glibc v2.31+, equivalent to ubuntu v20.04+) Mac OSX 11+ (M1/ARM or x64) Python 3.4 or later Please let us know if your configuration is unsupported. Installing DuckDB\u200b cautionMotherDuck currently supports DuckDB 1.3.2 and it is compatible with any client version 1.1.0 through 1.3.2 Use the following pip command to install the supported version of DuckDB: pip install duckdb==1.3.2 Connect to MotherDuck\u200b You can connect to and work with multiple local and MotherDuck-hosted DuckDB databases at the same time. Currently, the connection syntax varies depending on how you\u2019re opening local DuckDB and MotherDuck. Authenticating to MotherDuck\u200b You can authenticate to MotherDuck using either browser-based authentication or an access token. Here are examples of both methods: Using browser-based authentication\u200b import duckdb# connect to MotherDuck using 'md:' or 'motherduck:'con = duckdb.connect('md:') When you run this code: A URL and a code will be displayed in your terminal. Your default web browser will automatically open to the URL. You'll see a confirmation request to approve the connection. Once, approved, if you're not already logged in to MotherDuck, you'll be prompted to do so. Finally, you can close the browser tab and return to your Python environment. This method is convenient for interactive sessions and doesn't require managing access tokens. Using an access token\u200b For automated scripts or environments where browser-based auth isn't suitable, you can use an access token: import duckdb# Initiate a MotherDuck connection using an access tokencon = duckdb.connect('md:?motherduck_token=<your_access_token>') Replace <your_access_token> with an actual token generated from the MotherDuck UI. To learn more about creating and managing access tokens, as well as other authentication options, see our guide on Authenticating to MotherDuck. Connecting to MotherDuck\u200b Once you've authenticated, you can connect to MotherDuck and start working with your data. Let's look at a few common scenarios. Connecting directly to MotherDuck\u200b Here's how to connect to MotherDuck and run a simple query: import duckdb# Connect to MotherDuck via browser-based authenticationcon = duckdb.connect('md:my_db')# Run a query to verify the connectioncon.sql(\"SHOW DATABASES\").show() tipWhen connecting to MotherDuck, you need to specify a database name (like my_db in the example). If you're a new user, a default database called my_db is automatically created when your account is first set up. You can query any table in your connected database by just using its name. To switch databases, use the USE command. Working with both MotherDuck and local databases\u200b MotherDuck allows you to work with both cloud and local databases simultaneously. Here's how: import duckdb# Connect to MotherDuck first, specifying a databasecon = duckdb.connect('md:my_db')# Then attach local DuckDB databasescon.sql(\"ATTACH 'local_database1.duckdb'\")con.sql(\"ATTACH 'local_database2.duckdb'\")# List all connected databasescon.sql(\"SHOW DATABASES\").show() Adding MotherDuck to an existing local connection\u200b If you're already working with a local DuckDB database, you can easily add a MotherDuck connection: import duckdb# Start with a local DuckDB databaselocal_con = duckdb.connect('local_database.duckdb')# Add a MotherDuck connection, specifying a databaselocal_con.sql(\"ATTACH 'md:my_db'\") This is another approach to give you the flexibility to work with both local and cloud data in the same session.PreviousPythonNextSpecify MotherDuck databasePrerequisitesInstalling DuckDBConnect to MotherDuckAuthenticating to MotherDuckConnecting to MotherDuckMotherDuckDocs Pricing ProductOverview For Data Teams For App Devs For DuckDB Users Case Studies Ecosystem Startups Support Trust & Security CommunityBlog Slack Events YouTube Small Data SF Videos & Streams DuckDB News DuckDB Snippets Free DuckDB Book Learn Code of Conduct CompanyAbout Us Careers Quacking Contact Support MotherDuck is powered by DuckDBTerms of UsePrivacy PolicySupport Policy",
    "length": 4728
  },
  {
    "source": "motherduck_docs",
    "url": "https://motherduck.com/docs/getting-started/interfaces/client-apis/connect-query-from-python/choose-database/",
    "title": "Specify MotherDuck database | MotherDuck Docs",
    "content": "Specify MotherDuck database | MotherDuck Docs Skip to main contentSLACK COMMUNITYDUCKDB SNIPPETSBLOGllmsSearchSIGN UPGetting startedMotherDuck TutorialData WarehousingCustomer-Facing AnalyticsInterfacesClient APIsPythonInstallation & authenticationSpecify MotherDuck databaseLoading data into MotherDuckQuery dataCGoJava (JDBC)Node.jsODBCOthersRRustWebAssembly (Wasm)DuckDB CLIMotherDuck Web UIExample DatasetsReferenceHow-to guidesIntegrationsConceptsTroubleshootingAbout MotherDuckGetting startedInterfacesClient APIsPythonSpecify MotherDuck databaseCopy as MarkdownSpecify MotherDuck databaseWhen you connect to MotherDuck you can specify a database name or omit the database name and connect to the default database. If you use md: without a database name, you connect to a default MotherDuck database called my_db. If you use md:<database name>, you connect to the <database name> database. After you establish the connection, either the default database or the one you specify becomes the current database. You can run the USE command to switch the current database, as shown in the following example. #list the current databasecon.sql(\"SELECT current_database()\").show()# ('database1') #switch the current database to database2con.sql(\"USE database2\") To query a table in the current database, you can specify just the table name. To query a table in a different database, you can include the database name when you specify the table. You don't need to switch the current database. The following examples demonstrate each method. #querying a table in the current databasecon.sql(\"SELECT count(*) FROM mytable\").show()#querying a table in another databasecon.sql(\"SELECT count(*) FROM another_db.another_table\").show()PreviousInstallation & authenticationNextLoading data into MotherDuckMotherDuckDocs Pricing ProductOverview For Data Teams For App Devs For DuckDB Users Case Studies Ecosystem Startups Support Trust & Security CommunityBlog Slack Events YouTube Small Data SF Videos & Streams DuckDB News DuckDB Snippets Free DuckDB Book Learn Code of Conduct CompanyAbout Us Careers Quacking Contact Support MotherDuck is powered by DuckDBTerms of UsePrivacy PolicySupport Policy",
    "length": 2187
  },
  {
    "source": "motherduck_docs",
    "url": "https://motherduck.com/docs/getting-started/interfaces/client-apis/connect-query-from-python/loading-data-into-md/",
    "title": "Loading data into MotherDuck with Python | MotherDuck Docs",
    "content": "Loading data into MotherDuck with Python | MotherDuck Docs Skip to main contentSLACK COMMUNITYDUCKDB SNIPPETSBLOGllmsSearchSIGN UPGetting startedMotherDuck TutorialData WarehousingCustomer-Facing AnalyticsInterfacesClient APIsPythonInstallation & authenticationSpecify MotherDuck databaseLoading data into MotherDuckQuery dataCGoJava (JDBC)Node.jsODBCOthersRRustWebAssembly (Wasm)DuckDB CLIMotherDuck Web UIExample DatasetsReferenceHow-to guidesIntegrationsConceptsTroubleshootingAbout MotherDuckGetting startedInterfacesClient APIsPythonLoading data into MotherDuckCopy as MarkdownOn this pageLoading data into MotherDuck with PythonCopying a table from a local DuckDB database into MotherDuck\u200b You can currently use CREATE TABLE AS SELECT to load CSV, Parquet, and JSON files into MotherDuck from either local, Amazon S3, or https sources as shown in the following examples. # load from local machine into table mytable of the current/active used databasecon.sql(\"CREATE TABLE mytable AS SELECT * FROM '~/filepath.csv'\");# load from an S3 bucket into table mytable of the current/active databasecon.sql(\"CREATE TABLE mytable AS SELECT * FROM 's3://bucket/path/*.parquet'\") If the source data matches the table\u2019s schema exactly you can also use INSERT INTO, as shown in the following example. # append to table mytable in the currently selected database from S3con.sql(\"INSERT INTO mytable SELECT * FROM 's3://bucket/path/*.parquet'\") Copying an entire local DuckDB database To MotherDuck\u200b MotherDuck supports copying your currently opened DuckDB database into a MotherDuck database. The following example copies a local DuckDB database named localdb into a MotherDuck-hosted database named clouddb. # open the local dblocal_con = duckdb.connect(\"localdb.ddb\") # connect to MotherDucklocal_con.sql(\"ATTACH 'md:'\")# The from indicates the file to upload. An empty path indicates the current database local_con.sql(\"CREATE DATABASE clouddb FROM CURRENT_DATABASE()\") A local DuckDB database can also be copied by its file path: local_con = duckdb.connect(\"md:\")local_con.sql(\"CREATE DATABASE clouddb FROM 'localdb.ddb'\") See Loading Data into MotherDuck for more detail.PreviousSpecify MotherDuck databaseNextQuery dataCopying a table from a local DuckDB database into MotherDuckCopying an entire local DuckDB database To MotherDuckMotherDuckDocs Pricing ProductOverview For Data Teams For App Devs For DuckDB Users Case Studies Ecosystem Startups Support Trust & Security CommunityBlog Slack Events YouTube Small Data SF Videos & Streams DuckDB News DuckDB Snippets Free DuckDB Book Learn Code of Conduct CompanyAbout Us Careers Quacking Contact Support MotherDuck is powered by DuckDBTerms of UsePrivacy PolicySupport Policy",
    "length": 2724
  },
  {
    "source": "motherduck_docs",
    "url": "https://motherduck.com/docs/getting-started/interfaces/connect-query-from-duckdb-cli/",
    "title": "DuckDB CLI | MotherDuck Docs",
    "content": "DuckDB CLI | MotherDuck Docs Skip to main contentSLACK COMMUNITYDUCKDB SNIPPETSBLOGllmsSearchSIGN UPGetting startedMotherDuck TutorialData WarehousingCustomer-Facing AnalyticsInterfacesClient APIsDuckDB CLIMotherDuck Web UIExample DatasetsReferenceHow-to guidesIntegrationsConceptsTroubleshootingAbout MotherDuckGetting startedInterfacesDuckDB CLICopy as MarkdownOn this pageDuckDB CLIInstallation\u200b cautionMotherDuck currently supports DuckDB 1.3.2 and it is compatible with any client version 1.1.0 through 1.3.2 Download and install the DuckDB binary, depending on your operating system. WindowsmacOSLinux Download the 64-bit Windows binary here Extract the Zip File. There are two recommended options for installing on MacOS. You can install with Homebrew or download the binary.Install with Homebrew\u200bTo install DuckDB, you can use the following command in the Terminal:brew install duckdbAlternative: download the binary\u200b Download the binary here Extract the zip file. Download the Linux binary: For 64-bit, download the binary here For arm64/aarch64, download the binary here Extract the Zip File. For more information, see the DuckDB installation documentation. Run the DuckDB CLI\u200b Run DuckDB using the command: ./duckdb By default, DuckDB will start with an in-memory database and any changes will not be persisted. To create a persistent database in the DuckDB CLI, you can specify a new filename as the first argument to the duckdb command. Example: ./duckdb mydatabase.ddb Connect to MotherDuck\u200b You can connect to MotherDuck by executing the following in DuckDB CLI. DuckDB will automatically download and load the signed MotherDuck extension. ATTACH 'md:'; DuckDB will prompt you to authenticate with MotherDuck using your default web browser. Follow the instructions displayed in the terminal. Test your MotherDuck connection using the following command. It will run in the cloud to display a list of your MotherDuck databases. show databases; Congrats \ud83c\udf89 You are connected! Now you can create databases and switch between them. You can also connect to your local DuckDB databases alongside databases hosted in MotherDuck, and interact with both! To know more about how to persist your authentication credentials, read Authenticating to MotherDuck infoNote you can also connect to MotherDuck directly when starting DuckDB CLI by running the following command:duckdb \"md:\" Accessing the MotherDuck UI from the CLI:\u200b You can access the MotherDuck UI from the CLI by executing the following command in the terminal: duckdb -ui If you are already in a DuckDB session, you can instead use CALL start_ui(); Upgrading MotherDuck via the DuckDB CLI:\u200b If you have previously installed the extension, but we have upgraded the service, you may need to run the FORCE INSTALL command as shown in the following example. FORCE INSTALL motherduckPreviousWebAssembly (Wasm)NextMotherDuck Web UIInstallationInstall with HomebrewAlternative: download the binaryRun the DuckDB CLIConnect to MotherDuckAccessing the MotherDuck UI from the CLI:Upgrading MotherDuck via the DuckDB CLI:MotherDuckDocs Pricing ProductOverview For Data Teams For App Devs For DuckDB Users Case Studies Ecosystem Startups Support Trust & Security CommunityBlog Slack Events YouTube Small Data SF Videos & Streams DuckDB News DuckDB Snippets Free DuckDB Book Learn Code of Conduct CompanyAbout Us Careers Quacking Contact Support MotherDuck is powered by DuckDBTerms of UsePrivacy PolicySupport Policy",
    "length": 3468
  },
  {
    "source": "motherduck_docs",
    "url": "https://motherduck.com/docs/getting-started/interfaces/motherduck-quick-tour/",
    "title": "MotherDuck Web UI | MotherDuck Docs",
    "content": "MotherDuck Web UI | MotherDuck Docs Skip to main contentSLACK COMMUNITYDUCKDB SNIPPETSBLOGllmsSearchSIGN UPGetting startedMotherDuck TutorialData WarehousingCustomer-Facing AnalyticsInterfacesClient APIsDuckDB CLIMotherDuck Web UIExample DatasetsReferenceHow-to guidesIntegrationsConceptsTroubleshootingAbout MotherDuckGetting startedInterfacesMotherDuck Web UICopy as MarkdownOn this pageMotherDuck Web UILogin\u200b To log in to MotherDuck UI, please go to app.motherduck.com. You will be redirected to our web UI. infoNote you can also connect to the MotherDuck UI directly when starting DuckDB CLI by running the following command:duckdb \"md:\" -ui Main Window\u200b Executing a sample query\u200b After you log in, run the following SQL query: SELECT country_name, city, pm25_concentration AS pm25_pollutionFROM sample_data.who.ambient_air_qualityWHERE year=2019 AND pm25_concentration IS NOT NULLORDER BY pm25_pollution ASC This query accesses the Sample Data Database which is attached by default. MotherDuck executes this query in the cloud. Query results are saved into your browser into an interactive panel for fast data exploration with data sorting, filtering, and pivoting. You can also click the Expand button on the top right of each cell to expand the editor and results area. Diving into your data with Column Explorer\u200b Exploring tables or resultsets\u200bThe Column Explorer allows you to see stats on either a selected table or the resultset from the selected notebook cell.Seeing value frequencies\u200bFor each column, you'll see the column type, the most commonly-occurring values and the percentage of values that are NULL.In the case the values are numerical, you'll see a histogram visualization.Charting data over time\u200bIf you have timestamp data, you'll also see a chart in the Column Explorer with automatic binning over time. The Column Explorer is collapsible by clicking the toggle on the top right. Dig into your results in the Cell Content Pane\u200b Click on a cell in your results to see it's full contents. Interact with JSON values\u200b Expand, collapse, and copy content from JSON type columns. You can also copy the keypath to a specific value, or the value itself! Writing queries with Autocomplete\u200b MotherDuck Web UI supports autocomplete. As you write SQL in the UI, on every keystroke autocomplete brings up query syntax suggestions. You can turn off autocomplete in Web UI settings, found by clicking your profile in the top-left and choosing \"Settings\" followed by \"Preferences.\" Writing SQL with confidence using FixIt and Edit\u200b FixIt helps you resolve common SQL errors by offering fixes in-line. Edit helps you edit SQL queries with natural language prompts. Settings\u200b MotherDuck settings are found by clicking your profile at the top-left. These settings are specific to each MotherDuck user and organization. General: Access Tokens\u200b This section allows you to create access tokens, which can be use for programmatically authenticating to MotherDuck. Tokens can have expiry dates. Organization\u200b This section allows you to change the display name of the organization. You can also enable all users in your email domain to join you in your MotherDuck organization. See \"Managing Organizations\" for more information. Members\u200b Displays members with access to the organization and allows you to invite new members to join your MotherDuck organization. Members are defined as human users with logins and passwords as well as service accounts. Preferences: UI settings\u200b Enable autocomplete when typing Enable inline SQL error fix suggestions Secrets\u200b MotherDuck enables you to query cloud blob stores without supplying credentials each time. Currently, credentials are supported for AWS S3 and Azure Blob Storage, Google Cloud Storage (GCS), CloudFlare R2 and Hugging Face. Plans\u200b Shows your current plan (Free, Standard) and allows you to switch plans. Billing\u200b Displays your current plan, primary billing email address and estimated invoices and usage during free trial. After the free trial, you can see actual usage and access your invoices. Service Accounts (Admin only)\u200b Lists the service accounts in your organization, and lets you create, manage, and impersonate service accounts to test or troubleshoot workflows. Service accounts enable you to run automated workflows and integrations without using a personal user account. Instances\u200b Use this section to manage the instances associated with your user account. Instance Type\u200b Set the Read/Write and Read Scaling instance types for your user account. Read Scaling replica pool size\u200b Set the pool size for your user account's read-scaling replicas. Learn more about Read Scaling. Version Information\u200b The current MotherDuck remote version of DuckDB, MotherDuck Client version, and MotherDuck UI version in active use. Reset Duckling\u200b This option allows you to reset your account's Read/Write Duckling (instance) for troubleshooting purposes. Reach out to MotherDuck support for help troubleshooting when resetting your Duckling. Keyboard shortcuts\u200b MotherDuck supports the following keyboard shortcuts. Use Ctrl for Windows/Linux and \u2318 (Command) for Mac. Use Alt for Windows/Linux and \u2325 (Option) for Mac. CommandActionCtrl/\u2318 + EnterRun the current cell.Ctrl/\u2318 + Shift + EnterRun selected text in the current cell. If no text is selected, run the whole cell.Shift + Enter or Alt/\u2325 + EnterRun the current cell, then advance to the next cell, creating a new one if necessary.TabWhen editing a query, indent current line. When navigating the notebook, advance to next UI element/button.Shift + TabWhen editing a query, de-indent current line. When navigating the notebook, move to previous UI element/button.EscChange Tab key behavior to navigate the UI instead of indent/de-indent editor text. Once another cell is selected, Tab behavior reverts to indent/de-indent.Ctrl/\u2318 + /Toggle line comments on/off - prepends -- to the front each selected line.Ctrl/\u2318 + zUndo query edits within currently selected cell.Ctrl/\u2318 + Shift + zRedo query edits within currently selected cell.Ctrl/\u2318 + eToggle between worksheet and notebook view for the active cell.Ctrl/\u2318 + Shift + .Toggle Instant SQL mode on/off for the active cell.Ctrl/\u2318 + iToggle the results inspect (right-hand panel) on/off.Ctrl/\u2318 + bToggle the notebook & databse browser (left-hand panel) on/off.Ctrl/\u2318 + \u2191Move currently selected cell up.Ctrl/\u2318 + \u2193Move currently selected cell down.Ctrl/\u2318 + kOpen 'Edit' dialog.Ctrl/\u2318 + Alt/\u2325 + oFormat SQL in the current cell. When text is selected, only the selection is formatted.Ctrl/\u2318 + Shift + pOpen the command menu. noteHit Esc to allow Tab or Shift + Tab to no longer ident or de-indent current line and move to previous UI element instead.PreviousDuckDB CLINextExample DatasetsLoginMain WindowExecuting a sample queryDiving into your data with Column ExplorerExploring tables or resultsetsSeeing value frequenciesCharting data over timeDig into your results in the Cell Content PaneWriting queries with AutocompleteWriting SQL with confidence using FixIt and EditSettingsGeneral: Access TokensOrganizationMembersPreferences: UI settingsSecretsPlansBillingService Accounts (Admin only)InstancesKeyboard shortcutsMotherDuckDocs Pricing ProductOverview For Data Teams For App Devs For DuckDB Users Case Studies Ecosystem Startups Support Trust & Security CommunityBlog Slack Events YouTube Small Data SF Videos & Streams DuckDB News DuckDB Snippets Free DuckDB Book Learn Code of Conduct CompanyAbout Us Careers Quacking Contact Support MotherDuck is powered by DuckDBTerms of UsePrivacy PolicySupport Policy",
    "length": 7566
  },
  {
    "source": "motherduck_docs",
    "url": "https://motherduck.com/docs/sql-reference/motherduck-sql-reference/ai-functions/sql-assistant/prompt-query/",
    "title": "PROMPT_QUERY | MotherDuck Docs",
    "content": "PROMPT_QUERY | MotherDuck Docs Skip to main contentSLACK COMMUNITYDUCKDB SNIPPETSBLOGllmsSearchSIGN UPGetting startedReferenceMotherDuck SQLAISQL AssistantPROMPT_QUERYPROMPT_SQLPROMPT_EXPLAINPROMPT_FIX_LINEPROMPT_FIXUPPROMPT_SCHEMAEMBEDDINGPROMPTATTACHCOPY FROM DATABASE (OVERWRITE)COPY FROM DATABASECREATE DATABASECREATE SECRETCREATE SHARECREATE SNAPSHOTDROP SECRETDESCRIBE SHAREDETACHDROP DATABASEDROP SHAREEXPLAIN ANALYZEEXPLAINGRANT READ ON SHARELIST SECRETSLIST SHARESMD_RUN parameterPRINT_MD_TOKEN pragmaREFRESH DATABASEREVOKE READ ON SHARESHOW ALL DATABASESTEMPORARY TABLESUPDATE SHAREServer Connection ManagementMD_INFORMATION_SCHEMAAdmin APIDuckDB SyntaxMotherDuck Wasm ClientHow-to guidesIntegrationsConceptsTroubleshootingAbout MotherDuckReferenceMotherDuck SQLAISQL AssistantPROMPT_QUERYCopy as MarkdownOn this pagePROMPT_QUERYAnswer questions about your data\u200b The prompt_query pragma allows you to ask questions about your data in natural language. This feature translates your plain English questions into SQL, executes the query, and returns the results. Under the hood, MotherDuck analyzes your database schema, generates appropriate SQL and executes the query on your behalf. This makes data exploration and analysis accessible to users of all technical levels. infoThe prompt_query pragma is a read-only operation and does not allow queries that modify the database. Syntax\u200b PRAGMA prompt_query('<natural language question>') Parameters\u200b ParameterRequiredDescriptionquestionYesThe natural language question about your data Example usage\u200b Here are several examples using MotherDuck's sample Hacker News dataset from MotherDuck's sample data database. prompt_query can be used to answer both simple and complex questions. Basic questions\u200b -- Find the most shared domainsPRAGMA prompt_query('what are the top domains being shared on hacker_news?')-- Analyze posting patternsPRAGMA prompt_query('what day of the week has the most posts?')-- Identify trendsPRAGMA prompt_query('how has the number of posts changed over time?') Complex questions\u200b -- Multi-part analysisPRAGMA prompt_query('what are the top 5 domains with the highest average score, and how many stories were posted from each?')-- Time-based analysisPRAGMA prompt_query('compare the average score of posts made during weekdays versus weekends')-- Conditional filteringPRAGMA prompt_query('which users have posted the most stories about artificial intelligence or machine learning?') Best practices\u200b For the best results with prompt_query: Be specific: clearly state what information you're looking for Provide context: include relevant details about the data you want to analyze Use natural language: phrase your questions as you would ask a data analyst Start simple: begin with straightforward questions and build to more complex ones Refine iteratively: if results aren't what you expected, try rephrasing your question Limitations\u200b While prompt_query is powerful, be aware of these limitations: Only performs read operations (SELECT queries) Works best with well-structured data with clear column names Complex statistical analyses will likely require you (or an LLM) to write SQL Performance depends on the complexity of your question and database size May not understand highly domain-specific terminology without you giving more context Troubleshooting\u200b If you're not getting the expected results: Check that you're connected to the correct database Ensure your question is clear and specific Try rephrasing your question using different terms For complex analyses, break down into multiple simpler questions Notes\u200b MotherDuck AI operates on your current database by evaluating the schemas and contents of the database. To point MotherDuck AI at a specific database, execute the USE database command (learn more about switching databases). Usage limits are in place to safeguard your spend, not because of throughput limitations. MotherDuck has the capacity to handle high-volume workloads and is always open to working alongside customers to support any type of requirement. These capabilities are provided by MotherDuck's integration with OpenAI. For availability and pricing, see MotherDuck's Pricing Model. If you need higher usage limits or have specific requirements, please reach out to the Slack support channel or email support@motherduck.com.PreviousSQL AssistantNextPROMPT_SQLAnswer questions about your dataSyntaxParametersExample usageBest practicesLimitationsTroubleshootingNotesMotherDuckDocs Pricing ProductOverview For Data Teams For App Devs For DuckDB Users Case Studies Ecosystem Startups Support Trust & Security CommunityBlog Slack Events YouTube Small Data SF Videos & Streams DuckDB News DuckDB Snippets Free DuckDB Book Learn Code of Conduct CompanyAbout Us Careers Quacking Contact Support MotherDuck is powered by DuckDBTerms of UsePrivacy PolicySupport Policy",
    "length": 4872
  },
  {
    "source": "motherduck_docs",
    "url": "https://motherduck.com/docs/sql-reference/motherduck-sql-reference/ai-functions/sql-assistant/prompt-sql/",
    "title": "PROMPT_SQL | MotherDuck Docs",
    "content": "PROMPT_SQL | MotherDuck Docs Skip to main contentSLACK COMMUNITYDUCKDB SNIPPETSBLOGllmsSearchSIGN UPGetting startedReferenceMotherDuck SQLAISQL AssistantPROMPT_QUERYPROMPT_SQLPROMPT_EXPLAINPROMPT_FIX_LINEPROMPT_FIXUPPROMPT_SCHEMAEMBEDDINGPROMPTATTACHCOPY FROM DATABASE (OVERWRITE)COPY FROM DATABASECREATE DATABASECREATE SECRETCREATE SHARECREATE SNAPSHOTDROP SECRETDESCRIBE SHAREDETACHDROP DATABASEDROP SHAREEXPLAIN ANALYZEEXPLAINGRANT READ ON SHARELIST SECRETSLIST SHARESMD_RUN parameterPRINT_MD_TOKEN pragmaREFRESH DATABASEREVOKE READ ON SHARESHOW ALL DATABASESTEMPORARY TABLESUPDATE SHAREServer Connection ManagementMD_INFORMATION_SCHEMAAdmin APIDuckDB SyntaxMotherDuck Wasm ClientHow-to guidesIntegrationsConceptsTroubleshootingAbout MotherDuckReferenceMotherDuck SQLAISQL AssistantPROMPT_SQLCopy as MarkdownOn this pagePROMPT_SQLOverview\u200b The prompt_sql function allows you to generate SQL queries using natural language. Simply describe what you want to analyze in plain English, and MotherDuck AI will translate your request into a valid SQL query based on your database schema and content. This function helps users who are less familiar with SQL syntax to generate queries and experienced SQL users save time when working with unfamiliar schemas. Syntax\u200b CALL prompt_sql('<natural language question>'[, include_tables=<table_specification>]); Parameters\u200b ParameterTypeDescriptionRequirednatural language questionSTRINGYour query in plain English describing the data you want to analyzeYesinclude_tablesARRAY or MAPSpecifies which tables and columns to consider for query generation. When not provided, all tables in the current database will be considered.No Include tables parameter\u200b You can specify which tables and columns should be considered during SQL generation using the include_tables parameter. This is particularly useful when: You want to focus on specific tables in a large database You want to improve performance by reducing the schema analysis scope The parameter accepts three formats: Array of table names: include all columns from specified tables: include_tables=['table1', 'table2'] Map of tables to columns: include only specific columns from tables: include_tables={'table1': ['column1', 'column2'], 'table2': ['column3']} Map with column regex patterns: include columns matching patterns: include_tables={'table1': ['column_prefix.*', 'exact_column']} Examples\u200b Basic example\u200b Let's start with a simple example using MotherDuck's sample Hacker News dataset: CALL prompt_sql('what are the top domains being shared on hacker_news?'); Output: querySELECT regexp_extract(url, 'https?://([^/]+)') AS domain, COUNT(*) AS count FROM hn.hacker_news WHERE url IS NOT NULL GROUP BY domain ORDER BY count DESC; Intermediate example\u200b This example demonstrates how to generate a more complex query with filtering, aggregation, and time-based analysis: CALL prompt_sql('Show me the average score of stories posted by each author who has posted at least 5 stories in 2022, sorted by average score'); Output: querySELECT 'by', AVG(score) AS average_score FROM hn.hacker_news WHERE EXTRACT(YEAR FROM 'timestamp') = 2022 GROUP BY 'by' HAVING COUNT(id) >= 5 ORDER BY average_score; Advanced Example: Multi-table Analysis with Specific Columns\u200b This example shows how to generate a query that focuses on specific columns: CALL prompt_sql( 'Find the top 10 users who submitted the most stories with the highest average scores in 2023', include_tables={ 'hn.hacker_news': ['id', 'by', 'score', 'timestamp', 'type', 'title'] }); Output: querySELECT \"by\", AVG(score) AS avg_score, COUNT(*) AS story_count FROM hn.hacker_news WHERE \"type\" = 'story' AND EXTRACT(YEAR FROM \"timestamp\") = 2023 GROUP BY \"by\" ORDER BY story_count DESC, avg_score DESC LIMIT 10; Expert example\u200b This example demonstrates generating a complex query with subqueries, window functions, and complex logic: CALL prompt_sql('For each month in 2022, show me the top 3 users who posted stories with the highest scores, and how their average score compares to the previous month'); Output: queryWITH monthly_scores AS (SELECT \"by\" AS user, DATE_TRUNC('month', \"timestamp\") AS month, AVG(score) AS avg_score FROM hn.hacker_news WHERE \"type\" = 'story' AND DATE_PART('year', \"timestamp\") = 2022 GROUP BY user, month ), ... Failure example\u200b This example shows that for some complex queries, the model might not generate a valid SQL query. Therefore the output will be the following error message: CALL prompt_sql('Identify the most discussed technology topics in Hacker News stories from the past year based on title keywords, and show which days of the week have the highest engagement for each topic'); Output: queryInvalid Input Error: The AI could not generate valid SQL. Try re-running the command or rephrasing your question. To generate a valid SQL query, you can try to break down the question into simpler parts. Best practices\u200b Be specific in your questions: the more specific your natural language query, the more accurate the generated SQL will be. Start simple and iterate: begin with basic queries and gradually add complexity as needed. Use the include_tables parameter: when working with large databases, specify relevant tables to improve performance and accuracy. Review generated SQL: always review the generated SQL before executing it, especially for complex queries. Understand your schema: knowing your table structure helps you phrase questions that align with available data. Use domain-specific terminology: include field names in your questions when possible. Provide context in your questions: mention time periods, specific metrics, or business context to get more relevant results. Notes\u200b By default, all tables in the current database are considered. Use the include_tables parameter to narrow the scope. To target a specific database, first execute the USE <database_name> command (learn more about switching databases). The quality of generated SQL depends on the clarity of your natural language question and the quality of your database schema (table and column names). This feature is powered by MotherDuck's integration with OpenAI's language models. Troubleshooting\u200b If you encounter issues with the prompt_sql function, consider the following troubleshooting steps: Check your database schema: ensure that the tables and columns you're querying are present in the current database. Be specific in your questions: the more specific your natural language query, the more accurate the generated SQL will be. Use the include_tables parameter: when working with large databases, specify relevant tables to improve performance and accuracy. PreviousPROMPT_QUERYNextPROMPT_EXPLAINOverviewSyntaxParametersInclude tables parameterExamplesBasic exampleIntermediate exampleAdvanced Example: Multi-table Analysis with Specific ColumnsExpert exampleFailure exampleBest practicesNotesTroubleshootingMotherDuckDocs Pricing ProductOverview For Data Teams For App Devs For DuckDB Users Case Studies Ecosystem Startups Support Trust & Security CommunityBlog Slack Events YouTube Small Data SF Videos & Streams DuckDB News DuckDB Snippets Free DuckDB Book Learn Code of Conduct CompanyAbout Us Careers Quacking Contact Support MotherDuck is powered by DuckDBTerms of UsePrivacy PolicySupport Policy",
    "length": 7290
  },
  {
    "source": "motherduck_docs",
    "url": "https://motherduck.com/docs/sql-reference/motherduck-sql-reference/ai-functions/sql-assistant/prompt-explain/",
    "title": "PROMPT_EXPLAIN | MotherDuck Docs",
    "content": "PROMPT_EXPLAIN | MotherDuck Docs Skip to main contentSLACK COMMUNITYDUCKDB SNIPPETSBLOGllmsSearchSIGN UPGetting startedReferenceMotherDuck SQLAISQL AssistantPROMPT_QUERYPROMPT_SQLPROMPT_EXPLAINPROMPT_FIX_LINEPROMPT_FIXUPPROMPT_SCHEMAEMBEDDINGPROMPTATTACHCOPY FROM DATABASE (OVERWRITE)COPY FROM DATABASECREATE DATABASECREATE SECRETCREATE SHARECREATE SNAPSHOTDROP SECRETDESCRIBE SHAREDETACHDROP DATABASEDROP SHAREEXPLAIN ANALYZEEXPLAINGRANT READ ON SHARELIST SECRETSLIST SHARESMD_RUN parameterPRINT_MD_TOKEN pragmaREFRESH DATABASEREVOKE READ ON SHARESHOW ALL DATABASESTEMPORARY TABLESUPDATE SHAREServer Connection ManagementMD_INFORMATION_SCHEMAAdmin APIDuckDB SyntaxMotherDuck Wasm ClientHow-to guidesIntegrationsConceptsTroubleshootingAbout MotherDuckReferenceMotherDuck SQLAISQL AssistantPROMPT_EXPLAINCopy as MarkdownOn this pagePROMPT_EXPLAINExplain a query\u200b The prompt_explain table function allows MotherDuck AI to analyze and explain SQL queries in plain English. This feature helps you understand complex queries, verify that a query does what you intend, and learn SQL concepts through practical examples. tipThis function is particularly useful for understanding queries written by others or for automatically documenting your own queries for future reference. Syntax\u200b CALL prompt_explain('<SQL query>', [include_tables=['<table_name>', '<table_name>']]); Parameters\u200b ParameterRequiredDescriptionqueryYesThe SQL query to explaininclude_tablesNoArray of table names to consider for context (defaults to all tables in current database). Can also be a dictionary in the format {'table_name': ['column1', 'column2']} to specify which columns to include for each table. Example usage\u200b Here are several examples using MotherDuck's sample Hacker News dataset from MotherDuck's sample data database. Explaining a complex query\u200b CALL prompt_explain('SELECT COUNT(*) as domain_count, SUBSTRING(SPLIT_PART(url, ''//'', 2), 1, POSITION(''/'' IN SPLIT_PART(url, ''//'', 2)) - 1) as domain FROM hn.hacker_newsWHERE url IS NOT NULL GROUP BY domain ORDER BY domain_count DESC LIMIT 10;'); Output: when you run a prompt_explain query, you'll receive a single-column table with a detailed explanation: explanationThe query retrieves the top 10 most frequent domains from the url field in the hn.hacker_news table. It counts the occurrences of each domain by extracting the domain part from the URL (after the '//' and before the next '/'), groups the results by domain, and orders them in descending order of their count. The result includes the count of occurrences (domain_count) and the domain name itself (domain). Using dictionary format for include_tables\u200b You can specify which columns to include for each table using the dictionary format: CALL prompt_explain('SELECT u.id, u.name, COUNT(s.id) AS story_countFROM hn.users uLEFT JOIN hn.stories s ON u.id = s.user_idGROUP BY u.id, u.nameHAVING COUNT(s.id) > 5ORDER BY story_count DESCLIMIT 20;', include_tables={'hn.users': ['id', 'name'], 'hn.stories': ['id', 'user_id']}); This approach allows you to focus the explanation on only the relevant columns, which can be helpful for tables with many columns. How it works\u200b The prompt_explain function processes your query in several steps: Parsing: analyzes the SQL syntax to understand the query structure Schema analysis: examines the referenced tables and columns to understand the data model Operation analysis: identifies the operations being performed (filtering, joining, aggregating, etc.) Translation: converts the technical SQL into a clear, human-readable explanation Context addition: adds relevant context about the purpose and expected results of the query Best practices\u200b For the best results with prompt_explain: Provide complete queries: include all parts of the query for the most accurate explanation Use table aliases consistently: this helps the function understand table relationships Specify relevant tables: use the include_tables parameter for large databases Review explanations: verify that the explanation matches your understanding of the query Use for documentation: save explanations as comments in your code for future reference Notes\u200b MotherDuck AI operates on your current database by evaluating the schemas and contents of the database. You can specify which tables and columns should be considered using the optional include_tables parameter. By default, all tables in the current database are considered. To point MotherDuck AI at a specific database, execute the USE database command (learn more about switching databases). These capabilities are provided by MotherDuck's integration with OpenAI. For availability and pricing, see MotherDuck's Pricing Model. If you need higher usage limits or have specific requirements, please reach out to the Slack support channel or email support@motherduck.com.PreviousPROMPT_SQLNextPROMPT_FIX_LINEExplain a querySyntaxParametersExample usageBest practicesNotesMotherDuckDocs Pricing ProductOverview For Data Teams For App Devs For DuckDB Users Case Studies Ecosystem Startups Support Trust & Security CommunityBlog Slack Events YouTube Small Data SF Videos & Streams DuckDB News DuckDB Snippets Free DuckDB Book Learn Code of Conduct CompanyAbout Us Careers Quacking Contact Support MotherDuck is powered by DuckDBTerms of UsePrivacy PolicySupport Policy",
    "length": 5327
  },
  {
    "source": "motherduck_docs",
    "url": "https://motherduck.com/docs/sql-reference/motherduck-sql-reference/ai-functions/sql-assistant/prompt-fix-line/",
    "title": "PROMPT_FIX_LINE | MotherDuck Docs",
    "content": "PROMPT_FIX_LINE | MotherDuck Docs Skip to main contentSLACK COMMUNITYDUCKDB SNIPPETSBLOGllmsSearchSIGN UPGetting startedReferenceMotherDuck SQLAISQL AssistantPROMPT_QUERYPROMPT_SQLPROMPT_EXPLAINPROMPT_FIX_LINEPROMPT_FIXUPPROMPT_SCHEMAEMBEDDINGPROMPTATTACHCOPY FROM DATABASE (OVERWRITE)COPY FROM DATABASECREATE DATABASECREATE SECRETCREATE SHARECREATE SNAPSHOTDROP SECRETDESCRIBE SHAREDETACHDROP DATABASEDROP SHAREEXPLAIN ANALYZEEXPLAINGRANT READ ON SHARELIST SECRETSLIST SHARESMD_RUN parameterPRINT_MD_TOKEN pragmaREFRESH DATABASEREVOKE READ ON SHARESHOW ALL DATABASESTEMPORARY TABLESUPDATE SHAREServer Connection ManagementMD_INFORMATION_SCHEMAAdmin APIDuckDB SyntaxMotherDuck Wasm ClientHow-to guidesIntegrationsConceptsTroubleshootingAbout MotherDuckReferenceMotherDuck SQLAISQL AssistantPROMPT_FIX_LINECopy as MarkdownOn this pagePROMPT_FIX_LINEFix your query line-by-line\u200b The prompt_fix_line table function allows MotherDuck AI to correct specific lines in your SQL queries that contain syntax or spelling errors. Unlike prompt_fixup, which rewrites the entire query, this function targets only the problematic lines, making it faster and more precise for localized errors. tipThis function is ideal for fixing minor syntax errors in large queries where you want to preserve most of the original query structure and formatting. Syntax\u200b CALL prompt_fix_line('<SQL query>', error='<Error message>', [include_tables=['<table_name>', '<table_name>']]); Parameters\u200b ParameterRequiredDescriptionqueryYesThe SQL query that needs correctionerrorNoThe error message from the SQL parser (helps identify the problematic line)include_tablesNoArray of table names to consider for context (defaults to all tables in current database) Example usage\u200b Here are several examples using MotherDuck's sample Hacker News dataset from MotherDuck's sample data database. Fixing simple syntax errors\u200b -- Fixing a misspelled keyword with error messageCALL prompt_fix_line('SEELECT COUNT(*) as domain_count FROM hn.hackers', error='Parser Error: syntax error at or near \"SEELECT\"LINE 1: SEELECT COUNT(*) as domain_count FROM h... ^');-- Fixing a typo in a column nameCALL prompt_fix_line('SELECT user_id, titlee, score FROM hn.stories LIMIT 10');-- Fixing incorrect operator usageCALL prompt_fix_line('SELECT * FROM hn.stories WHERE score => 100'); Fixing errors in multi-line queries\u200b -- Fixing a specific line in a complex queryCALL prompt_fix_line('SELECT user_id, COUNT(*) AS post_count, AVG(scor) AS average_scoreFRUM hn.storiesGROUP BY user_idORDER BY post_count DESCLIMIT 10', error='Parser Error: syntax error at or near \"FRUM\"LINE 5: FRUM hn.stories ^'); Example output\u200b When you run a prompt_fix_line query, you'll receive a two-column table with the line number and corrected content: line_numberline_content1SELECT COUNT(*) as domain_count FROM hn.hackers For multi-line queries, only the problematic line is corrected: line_numberline_content5FROM hn.stories How it works\u200b The prompt_fix_line function processes your query in a targeted way: Error localization: uses the error message (if provided) to identify the specific line with issues Context analysis: examines surrounding lines to understand the query's structure and intent Targeted correction: fixes only the problematic line while preserving the rest of the query Line replacement: returns the corrected line with its line number for easy integration For example, when fixing a syntax error in a single line: CALL prompt_fix_line('SEELECT COUNT(*) as domain_count FROM hn.hackers', error='Parser Error: syntax error at or near \"SEELECT\"LINE 1: SEELECT COUNT(*) as domain_count FROM h... ^'); The function will focus only on line 1, correcting the misspelled keyword: line_numberline_content1SELECT COUNT(*) as domain_count FROM hn.hackers For multi-line queries with an error on a specific line: CALL prompt_fix_line('SELECT user_id, COUNT(*) AS post_count, AVG(scor) AS average_scoreFRUM hn.storiesGROUP BY user_idORDER BY post_count DESCLIMIT 10', error='Parser Error: syntax error at or near \"FRUM\"LINE 5: FRUM hn.stories ^'); The function will only correct line 5, leaving the rest of the query untouched: line_numberline_content5FROM hn.stories This allows you to apply the fix by replacing just the problematic line in your original query, which is especially valuable for large, complex queries where a complete rewrite would be disruptive. When multiple errors exist, you would run prompt_fix_line multiple times, fixing one line at a time: -- First fixCALL prompt_fix_line('SELECT user_id, COUNT(*) AS post_count, AVG(scor) AS average_scoreFRUM hn.storiesGROUP BY user_idORDER BY post_count DESCLIMIT 10', error='Parser Error: syntax error at or near \"FRUM\"LINE 5: FRUM hn.stories ^');-- After applying the first fix, run again for the second errorCALL prompt_fix_line('SELECT user_id, COUNT(*) AS post_count, AVG(scor) AS average_scoreFROM hn.storiesGROUP BY user_idORDER BY post_count DESCLIMIT 10', error='Parser Error: column \"scor\" does not existLINE 4: AVG(scor) AS average_score ^'); The second call would return: line_numberline_content4AVG(score) AS average_score Note: you need to run prompt_fix_line multiple times to fix all errors. Best practices\u200b For the best results with prompt_fix_line: Include the error message: the parser error helps pinpoint the exact issue Preserve query structure: use this function when you want to maintain most of your original query Fix one error at a time: to address multiple errors, run prompt_fix_line multiple times Include context: provide the complete query, not just the problematic line Be specific with table names: use the include_tables parameter for large databases Limitations\u200b While prompt_fix_line is efficient, be aware of these limitations: Only fixes syntax errors, not logical errors in query structure Accurate error messages help identify the problematic line and improve output May not be able to fix errors that span multiple lines Cannot fix issues related to missing tables or columns in your database Works best with standard SQL patterns and common table structures Troubleshooting\u200b If you're not getting the expected results: Ensure you've included the complete error message Check that the line numbers in the error message match your query For complex errors, try using prompt_fixup instead If multiple lines need fixing, address them one at a time Verify that your database schema is accessible to the function Notes\u200b MotherDuck AI operates on your current database by evaluating the schemas and contents of the database. You can specify which tables and columns should be considered using the optional include_tables parameter. By default, all tables in the current database are considered. To point MotherDuck AI at a specific database, execute the USE database command (learn more about switching databases). These capabilities are provided by MotherDuck's integration with OpenAI. For availability and pricing, see MotherDuck's Pricing Model. If you need higher usage limits or have specific requirements, please reach out to the Slack support channel or email support@motherduck.com.PreviousPROMPT_EXPLAINNextPROMPT_FIXUPFix your query line-by-lineSyntaxParametersExample usageExample outputBest practicesLimitationsTroubleshootingNotesMotherDuckDocs Pricing ProductOverview For Data Teams For App Devs For DuckDB Users Case Studies Ecosystem Startups Support Trust & Security CommunityBlog Slack Events YouTube Small Data SF Videos & Streams DuckDB News DuckDB Snippets Free DuckDB Book Learn Code of Conduct CompanyAbout Us Careers Quacking Contact Support MotherDuck is powered by DuckDBTerms of UsePrivacy PolicySupport Policy",
    "length": 7672
  },
  {
    "source": "motherduck_docs",
    "url": "https://motherduck.com/docs/sql-reference/motherduck-sql-reference/ai-functions/prompt/",
    "title": "PROMPT | MotherDuck Docs",
    "content": "PROMPT | MotherDuck Docs Skip to main contentSLACK COMMUNITYDUCKDB SNIPPETSBLOGllmsSearchSIGN UPGetting startedReferenceMotherDuck SQLAISQL AssistantEMBEDDINGPROMPTATTACHCOPY FROM DATABASE (OVERWRITE)COPY FROM DATABASECREATE DATABASECREATE SECRETCREATE SHARECREATE SNAPSHOTDROP SECRETDESCRIBE SHAREDETACHDROP DATABASEDROP SHAREEXPLAIN ANALYZEEXPLAINGRANT READ ON SHARELIST SECRETSLIST SHARESMD_RUN parameterPRINT_MD_TOKEN pragmaREFRESH DATABASEREVOKE READ ON SHARESHOW ALL DATABASESTEMPORARY TABLESUPDATE SHAREServer Connection ManagementMD_INFORMATION_SCHEMAAdmin APIDuckDB SyntaxMotherDuck Wasm ClientHow-to guidesIntegrationsConceptsTroubleshootingAbout MotherDuckReferenceMotherDuck SQLAIPROMPTCopy as MarkdownOn this pagePROMPT\ud83d\udca1Preview FeatureThis is a preview feature. Preview features may be operationally incomplete and may offer limited backward compatibility. Prompt Function\u200b The prompt function allows you to interact with Large Language Models (LLMs) directly from SQL. You can generate both free-form text and structured data outputs. The function supports OpenAI's gpt-5 series (gpt-5, gpt-5-mini, gpt-5-nano), gpt-4o-mini (default), gpt-4o, and the gpt-4.1 series. All models support single- and multi-row inputs, enabling batch processing. Consumption is measured in AI Units. When reasoning over table rows, one AI Unit equates to approximately: 480 rows responses with gpt-4o 8,000 rows responses with gpt-4o-mini 600 rows responses with gpt-4.1 3,000 rows responses with gpt-4.1-mini 12,000 rows responses with gpt-4.1-nano 720 rows responses with gpt-5 3,600 rows with gpt-5-mini 18,000 rows with gpt-5-nano These estimates assume an input size of 1,000 characters and response size of 250 characters. Syntax\u200b SELECT prompt('Write a poem about ducks'); -- returns a single cell table with the response Parameters\u200b ParameterRequiredDescriptionprompt_textYesThe text input to send to the modelmodelNoModel type: 'gpt-5', 'gpt-5-mini', 'gpt-5-nano', 'gpt-4o-mini' (default), 'gpt-4o', 'gpt-4.1', 'gpt-4.1-mini', or 'gpt-4.1-nano'temperatureNoModel temperature value between 0 and 1, default: 0.1. Lower values produce more deterministic outputs.structNoOutput schema as struct, e.g. {summary: 'VARCHAR', persons: 'VARCHAR[]'}. Will result in STRUCT output.struct_descrNoDescriptions for struct fields that will be added to the model's context, e.g. {summary: 'a 1 sentence summary of the text', persons: 'an array of all persons mentioned in the text'}json_schemaNoA JSON schema that adheres to OpenAI's structured output guide. Provides more flexibility than the struct/struct_descr parameters. Will result in JSON output. Note: The struct parameter supports enum types for classification tasks. Define enum types first using CREATE TYPE, then reference them in the struct schema (e.g., sentiment: 'sentiment_enum' or categories: 'category_enum[]' for arrays). Return Types\u200b The prompt function can return different data types depending on the parameters used: Without structure parameters: Returns VARCHAR With struct parameter: Returns a STRUCT with the specified schema (supports enum types for classification) With json_schema parameter: Returns JSON Example Usage\u200b Basic Text Generation\u200b -- Call gpt-4o-mini (default) to generate textSELECT prompt('Write a poem about ducks') AS response;-- Call gpt-4o with higher temperature for more creative outputsSELECT prompt('Write a poem about ducks', model:='gpt-4o', temperature:=1) AS response; Structured Output with Struct\u200b -- Extract structured information from text using struct parameterSELECT prompt('My zoo visit was amazing, I saw elephants, tigers, and penguins. The staff was friendly.', struct:={summary: 'VARCHAR', favourite_animals:'VARCHAR[]', star_rating:'INTEGER'}, struct_descr:={star_rating: 'visit rating on a scale from 1 (bad) to 5 (very good)'}) AS zoo_review; This returns a STRUCT value that can be accessed with dot notation: SELECT zoo_review.summary, zoo_review.favourite_animals, zoo_review.star_ratingFROM ( SELECT prompt('My zoo visit was amazing, I saw elephants, tigers, and penguins. The staff was friendly.', struct:={summary: 'VARCHAR', favourite_animals:'VARCHAR[]', star_rating:'INTEGER'}, struct_descr:={star_rating: 'visit rating on a scale from 1 (bad) to 5 (very good)'}) AS zoo_review); Structured Output with JSON Schema\u200b -- Extract structured information using JSON schemaSELECT prompt('My zoo visit was amazing, I saw elephants, tigers, and penguins. The staff was friendly.', json_schema := '{ \"name\": \"zoo_visit_review\", \"schema\": { \"type\": \"object\", \"properties\": { \"summary\": { \"type\": \"string\" }, \"sentiment\": { \"type\": \"string\", \"enum\": [\"positive\", \"negative\", \"neutral\"] }, \"animals_seen\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } } }, \"required\": [\"summary\", \"sentiment\", \"animals_seen\"], \"additionalProperties\": false }, \"strict\": true }') AS json_review; This returns a JSON value that, if saved, can be accessed using JSON extraction functions: SELECT json_extract_string(json_review, '$.summary') AS summary, json_extract_string(json_review, '$.sentiment') AS sentiment, json_extract(json_review, '$.animals_seen') AS animals_seenFROM ( SELECT prompt('My zoo visit was amazing, I saw elephants, tigers, and penguins. The staff was friendly.', json_schema := '{ ... }') AS json_review); Use Cases\u200b Text Generation\u200b Using the prompt function to write a poem about ducks: --- Prompt LLM to write a poem about ducksSELECT prompt('Write a poem about ducks') AS response; response'Beneath the whispering willow trees, Where ripples dance with wayward breeze, A symphony of quacks arise [...]' Summarization\u200b We use the prompt function to create a one-sentence summary of movie descriptions. The example is based on the sample movies dataset from MotherDuck's sample data database. --- Create a new table with summaries for the first 100 overview textsCREATE TABLE my_db.movies AS SELECT title, overview, prompt('Summarize this movie description in one sentence: ' || overview) AS summary FROM kaggle.movies LIMIT 100; If write access to the source table is available, the summary column can also be added in place: --- Update the existing table to add new column for summariesALTER TABLE my_db.movies ADD COLUMN summary VARCHAR;--- Populate the column with summariesUPDATE my_db.movies SET summary = prompt('Summarize this movie description in one sentence: ' || overview); The movies table now contains a new column summary with one-sentence summaries of the movies: SELECT title, overview, summary FROM my_db.movies; titleoverviewsummaryToy StoryLed by Woody, Andy's toys live happily [...]In \"Toy Story,\" Woody's jealousy of the new [...]JumanjiWhen siblings Judy and Peter discover [...]In this thrilling adventure, siblings Judy and [...]......... Structured Data Extraction\u200b The prompt function can be used to extract structured data from text. The example is based on the same sample movies dataset from MotherDuck's sample data database. This time we aim to extract structured metadata from the movie's overview description. We are interested in the main characters mentioned in the descriptions, as well as the movie's genre and a rating of how much action the movie contains, given a scale of 1 (no action) to 5 (lot of action). For this, we make use of the struct and struct_descr parameters, which will result in structured output. --- Update the existing table to add new column for structured metadataALTER TABLE my_db.movies ADD COLUMN metadata STRUCT(main_characters VARCHAR[], genre VARCHAR, action INTEGER);--- Populate the column with structured informationUPDATE my_db.movies SET metadata = prompt( overview, struct:={main_characters: 'VARCHAR[]', genre: 'VARCHAR', action: 'INTEGER'}, struct_descr:={ main_characters: 'an array of the main character names mentioned in the movie description', genre: 'the primary genre of the movie based on the description', action: 'rate on a scale from 1 (no action) to 5 (high action) how much action the movie co",
    "length": 14712
  }
]